{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Video fork of Infinite patterns by Alexander Mordvintsev",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/16A0/til/blob/master/Video_fork_of_Infinite_patterns_by_Alexander_Mordvintsev.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaBXW2_cWj4y",
        "colab_type": "text"
      },
      "source": [
        "# Infinite patterns by Alexander Mordvintsev *(video fork)*\n",
        "\n",
        "\n",
        "with &nbsp; <img src=\"https://artsandculture.withgoogle.com/naturalhistorymuseum/images/logo-black.svg\" alt=\"drawing\" width=\"200\" style=\"margin-top:-10px;\"/>\n",
        "<p>&nbsp;</p>\n",
        "\n",
        "![alt text](https://storage.googleapis.com/cilex-common/temp/infinite-patterns-notebook-imgs/deepdream.png)\n",
        "\n",
        "Google’s **Alexander Mordvintsev** is the creator of DeepDream, a computer vision program that uses a neural network to find and create patterns in images. The end result often leads to dream-like, hallucinogenic, hyper-processed images.\n",
        "\n",
        "## Available to everyone\n",
        "\n",
        "The idea for Infinite Patterns came from a trip to the [Google Arts & Culture Lab](https://experiments.withgoogle.com/collection/arts-culture) in Paris, where [Pinar&Viola](https://www.pinar-viola.com/) saw images created by [DeepDream](https://en.wikipedia.org/wiki/DeepDream) first hand – and noticed similarities between the neural network’s creations and their own body of work. Noticing an opportunity for collaboration, “it felt as if all we have ever done in our career was done to bring us here,” said the artists.\n",
        "\n",
        "In December 2018, Pinar&Viola joined the lab as artists-in-residence, where they were able to work with Alex in the creation of new work. **Alex created a tool for the artists**, allowing them to create infinite patterns with DeepDream. First, the artists curated a selection of pictures, which were fed into the neural nets tool to extract inspiring patterns. Next, they combined these ML patterns with the original images to create the final design.\n",
        "\n",
        "**Today, the tool made by Alexander is available for you to use in the creation of your own art works!**\n",
        "\n",
        "This tools can create a pattern from any picture. More info about how the algorithms works [here](https://distill.pub/2018/differentiable-parameterizations/). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5gHiq3IbNY-",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "# *Fork notes*\n",
        "\n",
        "This is a copy/fork of Infinite Patterns that has been modified to add additional features like frame-by-frame export to Google Drive, tiling of outputs and the conversion of frames into videos. Additionally a further parameter, iterations, has been exposed in the controls: use this to help control how many frames of output you would like. The deep dream function hasn't been given any adjustments *(yet)* and has therefore been removed *(for now)*.\n",
        "\n",
        "In order to get started quickly it's recommended you click on \"File\" and \"Save a Copy in Drive...\". \n",
        "\n",
        "Please remember to check out the original project page & google colab document [here](https://experiments.withgoogle.com/infinitepatterns) if you haven't already *(It's totally awesome!)*.\n",
        "\n",
        "\n",
        "*A fork by [Dark Fractures](https://darkfractures.com) & [Sofia Crespo](https://https://sofiacrespo.com/))*\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDiQGivMMIPh",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title ← Load dependencies\n",
        "try:\n",
        "  import lucid\n",
        "except ImportError:\n",
        "  !pip install -q lucid\n",
        "\n",
        "from __future__ import print_function\n",
        "import os\n",
        "import io\n",
        "import string\n",
        "import numpy as np\n",
        "import PIL\n",
        "import base64\n",
        "from glob import glob\n",
        "import glob\n",
        "import itertools\n",
        "\n",
        "import cv2\n",
        "\n",
        "import matplotlib.pylab as pl\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib import slim\n",
        "\n",
        "import IPython\n",
        "from IPython.display import clear_output, Image, display, HTML\n",
        "\n",
        "from google.colab import files\n",
        "from google.colab import output\n",
        "from google.colab import drive\n",
        "\n",
        "from lucid.modelzoo import vision_models\n",
        "import lucid.misc.io.showing as show\n",
        "from lucid.optvis import objectives\n",
        "from lucid.optvis import render\n",
        "from lucid.misc.tfutil import create_session\n",
        "from lucid.optvis import style\n",
        "from lucid.modelzoo.util import forget_xy\n",
        "\n",
        "from google.colab import drive\n",
        "import image\n",
        "from itertools import count\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy0Fs7UZ21ak",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title ← Click this button to upload a different image\n",
        "\n",
        "def imwrite(fn, img):\n",
        "  if len(img.shape) == 4:\n",
        "    img = img[0]\n",
        "  img = np.uint8(img.clip(0, 1)*255)\n",
        "  im = PIL.Image.fromarray(img)\n",
        "  im.save(fn, quality=95)\n",
        "  \n",
        "def show_tiled_image(img):\n",
        "  url = show._image_url(img, fmt='jpeg')\n",
        "  h, w = img.shape[:2]\n",
        "\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "  #scroll {{\n",
        "    display: block;\n",
        "    background: url(\"{url}\") repeat 0 0;\n",
        "    width: 100%;\n",
        "    height: 512px;\n",
        "    animation: anim 10s linear infinite;\n",
        "    animation-play-state: paused; \n",
        "  }}\n",
        "  #scroll:hover {{\n",
        "    animation-play-state: running;\n",
        "  }}\n",
        "  #scroll img {{\n",
        "    height: 512px;\n",
        "    width: 512px;\n",
        "  }}\n",
        "  @keyframes anim {{\n",
        "    from {{ background-position: 0 0; }}\n",
        "    to {{ background-position: -{w}px -{h}px; }}\n",
        "  }}\n",
        "  a {{\n",
        "    background: rgba(255,255,255,.9);\n",
        "    padding: 5px;\n",
        "  }}\n",
        "  \n",
        "  </style>\n",
        "  <div id='scroll'><a href=\"{url}\" download='output.jpg'>download</a></div>\n",
        "  '''.format(url=url, h=h, w=w)))\n",
        "\n",
        "\n",
        "def anorm(a, axis=None, keepdims=False):\n",
        "  return (a*a).sum(axis=axis, keepdims=keepdims)**0.5\n",
        "\n",
        "\n",
        "def composite_activation(x):\n",
        "  x = tf.atan(x)\n",
        "  # Coefficients computed by:\n",
        "  #   def rms(x):\n",
        "  #     return np.sqrt((x*x).mean())\n",
        "  #   a = np.arctan(np.random.normal(0.0, 1.0, 10**6))\n",
        "  #   print(rms(a), rms(a*a))\n",
        "  return tf.concat([x/0.67, (x*x)/0.6], -1)\n",
        "\n",
        "\n",
        "def composite_activation_unbiased(x):\n",
        "  x = tf.atan(x)\n",
        "  # Coefficients computed by:\n",
        "  #   a = np.arctan(np.random.normal(0.0, 1.0, 10**6))\n",
        "  #   aa = a*a\n",
        "  #   print(a.std(), aa.mean(), aa.std())\n",
        "  return tf.concat([x/0.67, (x*x-0.45)/0.396], -1)\n",
        "\n",
        "\n",
        "def relu_normalized(x):\n",
        "  x = tf.nn.relu(x)\n",
        "  # Coefficients computed by:\n",
        "  #   a = np.random.normal(0.0, 1.0, 10**6)\n",
        "  #   a = np.maximum(a, 0.0)\n",
        "  #   print(a.mean(), a.std())\n",
        "  return (x-0.40)/0.58\n",
        "\n",
        "\n",
        "def image_cppn(\n",
        "    size,\n",
        "    offset=0.0,\n",
        "    num_output_channels=3,\n",
        "    num_hidden_channels=24,\n",
        "    num_layers=8,\n",
        "    activation_fn=composite_activation,\n",
        "    normalize=False):\n",
        "  coord_range = tf.to_float(tf.range(size))/tf.to_float(size)*2.0*np.pi\n",
        "  #coord_range = tf.linspace(-np.pi, np.pi, size)\n",
        "  y, x = tf.meshgrid(coord_range, coord_range, indexing='ij')\n",
        "  net = tf.expand_dims(tf.stack([x, y], -1), 0)  # add batch dimension\n",
        "  net += offset\n",
        "  net = tf.concat([tf.sin(net), tf.cos(net)], -1)\n",
        "  \n",
        "\n",
        "  with slim.arg_scope([slim.conv2d], kernel_size=1, activation_fn=None):\n",
        "    for i in range(num_layers):\n",
        "      in_n = int(net.shape[-1])\n",
        "      net = slim.conv2d(\n",
        "          net, num_hidden_channels,\n",
        "          # this is untruncated version of tf.variance_scaling_initializer\n",
        "          weights_initializer=tf.random_normal_initializer(0.0, np.sqrt(1.0/in_n)),\n",
        "      )\n",
        "      if normalize:\n",
        "        net = slim.instance_norm(net)\n",
        "      net = activation_fn(net)\n",
        "      \n",
        "    rgb = slim.conv2d(net, num_output_channels, activation_fn=tf.nn.sigmoid,\n",
        "                      weights_initializer=tf.zeros_initializer())\n",
        "  return rgb\n",
        "\n",
        "\n",
        "\n",
        "def render_graph(fn, size=224, stripe_width=256):\n",
        "  graph_def = tf.GraphDef.FromString(open(fn, 'rb').read())\n",
        "  g = tf.Graph()\n",
        "  with g.as_default():\n",
        "    tf.import_graph_def(graph_def, name='')\n",
        "  with tf.Session(graph=g) as sess:\n",
        "    ty, tx = 'meshgrid/mul:0', 'meshgrid/mul_1:0'\n",
        "    y, x = sess.run([ty, tx], {'size:0': size})\n",
        "    stripes = []\n",
        "    for s in range(0, len(x), stripe_width):\n",
        "      stripe = sess.run('image:0', \n",
        "                     {tx: x[s:s+stripe_width], ty: y[s:s+stripe_width]})\n",
        "      stripes.append(stripe[0])\n",
        "  return np.vstack(stripes)\n",
        "\n",
        "\n",
        "model = vision_models.InceptionV1_caffe()\n",
        "model.load_graphdef()\n",
        "\n",
        "print('\\n↓ Now click the \"Choose Files\" button and select an image\\n')\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "image_name, _ = uploaded.popitem()\n",
        "\n",
        "clear_output()\n",
        "\n",
        "im = PIL.Image.open(image_name)\n",
        "g_image = np.float32(im)[...,:3]/255.0\n",
        "show.image(g_image)\n",
        "\n",
        "print('\\rimage uploaded, size:', im.size, end='')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCUg1I2BJxS_",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Mount Google Drive\n",
        "#@markdown Mount google drive & specify folder that will be created in your Google Drive, all the output will be stored here. Please follow the instructions in order to authorize Colab to write files to your Google Drive (follow the link below).\n",
        "gdrive_folder = \"your_export_folder\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "%cd /content/gdrive/My Drive/\n",
        "!mkdir $gdrive_folder\n",
        "%cd $gdrive_folder\n",
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbPlSLt_FWwG",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title ← Click this button to render\n",
        "#@markdown # CPPN pattern tool\n",
        "#@markdown This tool uses simple neural networks that map pixel coordinates to colors to represent image, that gets optimized. This approach is also known as [Compositional pattern-producing network](https://en.wikipedia.org/wiki/Compositional_pattern-producing_network).\n",
        "#@markdown Optimization tries to generate an image, that produces activation pattern, similar to the target image, in a particular layer (defined by **layer_index**) of ImageNet-trained classification network. **v1** objective tries to match the average pattern, while **v2** tries to match the whole distrubution.\n",
        "#@markdown **style_weight** parameter defines the contribution of [Gatys et al](https://arxiv.org/abs/1508.06576) style loss, and ignored in case of **v2** objective.\n",
        "#@markdown **activation** function used in the image-generating CPPN influence the resulting image style.\n",
        "import imageio\n",
        "\n",
        "objective = 'v2' #@param ['v1', 'v2']\n",
        "activation = 'composite' #@param ['composite', 'relu']\n",
        "style_weight = 2 #@param {type: \"slider\", min: 0.0, max: 2.0, step:0.01}\n",
        "layer_index = 7 #@param {type: \"slider\", min: 2, max: 8}\n",
        "iterations = 3000 #@param {type:\"integer\"}\n",
        "google_drive_folder = \"\"\n",
        "\n",
        "\n",
        "sess = create_session()\n",
        "\n",
        "t_size = tf.placeholder_with_default(224, [], name='size')\n",
        "t_offset = tf.placeholder_with_default([0.0, 0.0], [2], name='offset')\n",
        "if activation == 'relu':\n",
        "  t_image = image_cppn(t_size, normalize=True, activation_fn=tf.nn.relu)\n",
        "elif activation == 'composite':\n",
        "  t_image = image_cppn(t_size, t_offset, normalize=False, activation_fn=composite_activation_unbiased)\n",
        "t_image = forget_xy(t_image)\n",
        "t_image = tf.identity(t_image, 'image')\n",
        "\n",
        "model.import_graph(t_image)\n",
        "\n",
        "tensor_name = 'import/%s:0'%model.layers[layer_index].name\n",
        "tensor = sess.graph.get_tensor_by_name(tensor_name)\n",
        "act = sess.run(tensor_name, {t_image:g_image[None, :,:,:3]})\n",
        "\n",
        "if objective=='v2':\n",
        "  act = act.reshape(-1, act.shape[-1])\n",
        "  act /= anorm(act, -1, True)\n",
        "\n",
        "  flat_tensor = tf.reshape(tensor, [-1, act.shape[-1]])\n",
        "  flat_tensor /= tf.norm(flat_tensor, axis=-1, keepdims=True)\n",
        "\n",
        "  cross = tf.matmul(flat_tensor, act, transpose_b=True)\n",
        "  t_loss0 = -tf.reduce_mean(tf.reduce_max(cross, 0))\n",
        "  t_loss1 = -tf.reduce_mean(tf.reduce_max(cross, 1))\n",
        "  t_loss = t_loss0 + t_loss1 - tf.reduce_mean(tensor)*0.05\n",
        "else:\n",
        "  target_act = act.mean((0, 1, 2))\n",
        "  t_dd_loss = -tf.reduce_mean(tensor*target_act)\n",
        "  sl = style.StyleLoss([tensor], loss_func=style.mean_l1_loss)\n",
        "  t_loss = t_dd_loss + sl.style_loss*style_weight\n",
        "\n",
        "t_lr = tf.constant(0.003)\n",
        "trainer = tf.train.AdamOptimizer(t_lr)\n",
        "train_op = trainer.minimize(t_loss)\n",
        "\n",
        "init_op = tf.global_variables_initializer()\n",
        "init_op.run()\n",
        "if objective=='v1':\n",
        "  sl.set_style({t_image:g_image[None,...]})\n",
        "\n",
        "init_op.run()\n",
        "\n",
        "frame_count = 00\n",
        "try:\n",
        "  for i in range(iterations+1):\n",
        "    dx, dy = np.random.rand(2)*np.pi*2\n",
        "    _, loss = sess.run([train_op, t_loss], {t_offset:[dx, dy]})\n",
        "   \n",
        "    if i%50 == 0:\n",
        "      clear_output()\n",
        "      show.image(sess.run(t_image), format='jpeg')\n",
        "#      adding download options per image\n",
        "      img_temp = sess.run(t_image, {t_size:1024})\n",
        "#      show_tiled_image(img_temp)\n",
        "      print(i, loss)\n",
        "      filename = 'data_%d'% frame_count\n",
        "      file_path = '/content/gdrive/My Drive/{}/{}.jpg'.format(gdrive_folder, filename)\n",
        "      print(file_path)\n",
        "      img = sess.run(t_image, {t_size:1024})[0]\n",
        "      imwrite('%s'% file_path, img)\n",
        "      frame_count+=1  \n",
        "except KeyboardInterrupt:\n",
        "  pass\n",
        "\n",
        "print('Patterns generated!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdDGXvR28ma1",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title ← Click this button to rename files for ffmpeg processing / tiling + ffmpeg\n",
        "#@markdown Adds a numerical iteration to the beginning of the filenames, necessary if you want to convert frames to video and/or tile output.\n",
        "\n",
        "%cd /content/gdrive/My Drive/\n",
        "%cd $gdrive_folder\n",
        "!pwd\n",
        "\n",
        "sorted_files = sorted(\n",
        "    glob.glob('*.jpg'), key=os.path.getmtime)\n",
        "\n",
        "for i, f in enumerate(sorted_files, 1):\n",
        "    try:\n",
        "        head, tail = os.path.split(f)\n",
        "\n",
        "        os.rename(f, os.path.join(head[:4], str(i).zfill(3)  + '_' + tail[:4] + '.jpg'))\n",
        "    except OSError:\n",
        "        print('Invalid operation')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqg0-4xPy8E_",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title ← Tiling of images\n",
        "#@markdown Adjust tiling from 1x1 to 4x4 (or any variant inbetween) with the sliders below. Additionally you may choose another name for the output folder.\n",
        "width = 4 #@param {type:\"slider\", min:1, max:4, step:1}\n",
        "height = 4 #@param {type:\"slider\", min:1, max:4, step:1}\n",
        "tiled_output_folder = \"tiled_output\" #@param {type:\"string\"}\n",
        "\n",
        "%cd /content/gdrive/My Drive/\n",
        "%cd $gdrive_folder\n",
        "!pwd\n",
        "!mkdir $tiled_output_folder\n",
        "\n",
        "working_folder = '/content/gdrive/My Drive/{}'.format(gdrive_folder)\n",
        "\n",
        "  \n",
        "for filename in os.listdir('%s' % working_folder):\n",
        "  if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        " #   print(os.path.join(filename))\n",
        "    file_path = '{}'.format(filename)\n",
        "    tiled_folder = tiled_output_folder\n",
        "    filename_export = '/content/gdrive/My Drive/{}/{}/tiled_{}'.format(gdrive_folder, tiled_folder, filename)\n",
        "    \n",
        "    img_to_tile = Image.open('%s'% file_path)\n",
        "    itt_copy = img_to_tile.copy()\n",
        "\n",
        "    tiled_img_height = int(height) * 1024\n",
        "    tiled_img_width = int(width) * 1024\n",
        "\n",
        "    tiled_img = Image.new('RGB', (int(tiled_img_width), int(tiled_img_height)), color = 'red')\n",
        "\n",
        "    tiled_img.paste(itt_copy, (0, 0))\n",
        "    tiled_img.paste(itt_copy, (0, 1024))\n",
        "    tiled_img.paste(itt_copy, (0, 2048))\n",
        "    tiled_img.paste(itt_copy, (0, 3072))\n",
        "    tiled_img.paste(itt_copy, (1024, 0))\n",
        "    tiled_img.paste(itt_copy, (1024, 1024))\n",
        "    tiled_img.paste(itt_copy, (1024, 1024))\n",
        "    tiled_img.paste(itt_copy, (1024, 2048))\n",
        "    tiled_img.paste(itt_copy, (1024, 3072))\n",
        "    tiled_img.paste(itt_copy, (2048, 0))\n",
        "    tiled_img.paste(itt_copy, (2048, 1024))\n",
        "    tiled_img.paste(itt_copy, (2048, 1024))\n",
        "    tiled_img.paste(itt_copy, (2048, 2048))\n",
        "    tiled_img.paste(itt_copy, (2048, 3072))\n",
        "    tiled_img.paste(itt_copy, (3072, 0))\n",
        "    tiled_img.paste(itt_copy, (3072, 1024))\n",
        "    tiled_img.paste(itt_copy, (3072, 1024))\n",
        "    tiled_img.paste(itt_copy, (3072, 2048))\n",
        "    tiled_img.paste(itt_copy, (3072, 3072))\n",
        "\n",
        "    tiled_img.save('%s' % filename_export)\n",
        "  else:\n",
        "    continue\n",
        "\n",
        "print('Tiling successful completed!')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-VMJvYuYoDs",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title ← Click this button to convert single images into movie\n",
        "#@markdown The resulting video file is saved into the same folder as the one you created in Google Drive.\n",
        "%cd /content/gdrive/My Drive/\n",
        "%cd $gdrive_folder\n",
        "!ffmpeg -start_number 001 -r 25 -i ./%3d_data.jpg -c:v libx264 -pix_fmt yuv420p ./output_single_tile.mov\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H09P3plDU-7a",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title ← Click this button to download movie *(from single images)*\n",
        "#@markdown *(can sometimes fail, click button again if so)*\n",
        "from google.colab import files\n",
        "!ls *.mov\n",
        "files.download('output_single_tile.mov')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgaDwkTY096",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title ← Click this button to convert tiled images into movie\n",
        "#@markdown The resulting video is saved to the tiled output folder.\n",
        "%cd /content/gdrive/My Drive/\n",
        "%cd $gdrive_folder\n",
        "%cd $tiled_output_folder\n",
        "!ffmpeg -start_number 001 -r 25 -i ./tiled_%3d_data.jpg -c:v libx264 -pix_fmt yuv420p -vf \"scale='if(gte(iw,ih),min(1024,iw),-2):if(lt(iw,ih),min(1024,ih),-2)'\" ./output_tiled.mov"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zoIRBjQgVPQu",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title ← Click this button to download movie *(from tiled images)*\n",
        "#@markdown *(can sometimes fail, click button again if so)*\n",
        "from google.colab import files\n",
        "!ls *.mov\n",
        "files.download('output_tiled.mov')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}